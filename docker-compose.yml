version: "3.8"
services:
    zookeeper:
        image: confluentinc/cp-zookeeper:latest
        container_name: zookeeper
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        ports:
            - "2181:2181"
        networks:
            - msa_network

    kafka:
        image: confluentinc/cp-kafka:latest
        container_name: kafka
        depends_on:
            - zookeeper
        environment:
            KAFKA_BROKER_ID: 1
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
            # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9092
            KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
            KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
            KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        ports:
            - "9092:9092"
            - "29092:29092"
        networks:
            - msa_network
        healthcheck:
            test:
                [
                    "CMD",
                    "kafka-topics",
                    "--list",
                    "--bootstrap-server",
                    "localhost:9092",
                ]
            interval: 10s
            timeout: 5s
            retries: 10

    redis:
        image: redis:latest
        container_name: redis
        ports:
            - "6379:6379"
        networks:
            - msa_network
        healthcheck:
            test: ["CMD", "redis-cli", "--raw", "ping"]
            interval: 5s
            timeout: 3s
            retries: 5

    postgres_auth:
        image: postgres:latest
        container_name: postgres_auth
        restart: always
        environment:
            POSTGRES_DB: flix
            POSTGRES_USER: dydwls140 # DB 사용자명
            POSTGRES_PASSWORD: "@astems1027" # DB 비밀번호
        ports:
            - "5432:5432"
        volumes:
            - postgres_auth_data:/var/lib/postgresql/data # 데이터 영구 저장
            # - ./postgres-init:/docker-entrypoint-initdb.d # 초기 SQL 실행
        networks:
            - msa_network

    postgres_streaming:
        image: postgres:latest
        container_name: postgres_streaming
        restart: always
        environment:
            POSTGRES_DB: flix
            POSTGRES_USER: dydwls140 # DB 사용자명
            POSTGRES_PASSWORD: "@astems1027" # DB 비밀번호
        ports:
            - "5431:5432"
        volumes:
            - postgres_streaming_data:/var/lib/postgresql/data # 데이터 영구 저장
            # - ./postgres-init:/docker-entrypoint-initdb.d # 초기 SQL 실행
        networks:
            - msa_network

    elasticsearch:
        image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
        container_name: elasticsearch
        environment:
            - discovery.type=single-node
            - ES_JAVA_OPTS=-Xms1g -Xmx1g
            - bootstrap.memory_lock=true # 메모리 잠금 활성화 (호스트에서 memlock 설정 필요)
        ulimits:
            memlock:
                soft: -1
                hard: -1
        ports:
            - "9200:9200"
            - "9300:9300"
        volumes:
            - esdata:/usr/share/elasticsearch/data
        networks:
            - msa_network

    logstash:
        image: docker.elastic.co/logstash/logstash:7.10.0
        container_name: logstash
        depends_on:
            - elasticsearch
        ports:
            - "5044:5044" # Beats input 등 사용 시
        volumes:
            # Logstash 설정 파일 및 파이프라인 정의 파일을 로컬에서 매핑합니다.
            - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
            - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
        networks:
            - msa_network

    kibana:
        image: docker.elastic.co/kibana/kibana:7.10.0
        container_name: kibana
        depends_on:
            - elasticsearch
        ports:
            - "5601:5601"
        networks:
            - msa_network

    filebeat:
        image: docker.elastic.co/beats/filebeat:7.10.0
        container_name: filebeat
        user: root
        volumes:
            - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
            - ./logs:/logs:ro
        networks:
            - msa_network
        depends_on:
            kafka:
                condition: service_healthy
        # entrypoint: "filebeat -e -strict.perms=false"
        command: ["filebeat", "-e", "-strict.perms=false"]

    auth-service:
        build: ../flix-auth
        container_name: auth-service
        ports:
            - "8050:8050"
        environment:
            - SPRING_PROFILES_ACTIVE=dev
        depends_on:
            postgres_auth:
                condition: service_started
        networks:
            - msa_network
        env_file:
            - ../flix-auth/.env
    # streaming-service:
    #     build: .
    #     container_name: streaming-service
    #     ports:
    #         - "8051:8051"
    #     environment:
    #         - SPRING_PROFILES_ACTIVE=dev
    #         - DB_HOST="postgres_streaming:5432"

    #     depends_on:
    #         - postgres_streaming
    #     networks:
    #         - msa_network
    session-service:
        build: ../flix-session
        container_name: session-service
        ports:
            - "8052:8052"
        environment:
            - SPRING_PROFILES_ACTIVE=dev
            - SPRING_REDIS_HOST=redis
            - SPRING_REDIS_PORT=6379
        depends_on:
            - redis
        networks:
            - msa_network
        env_file:
            - ../flix-session/.env

    config-server:
        build: ../config_server
        container_name: config-server
        environment:
            SPRING_PROFILES_ACTIVE: dev
        ports:
            - "8058:8058"
        networks:
            - msa_network
        env_file:
            - ../config_server/.env

volumes:
    postgres_auth_data:
        external: true
    postgres_streaming_data:
        external: true
    esdata:

networks:
    msa_network:
        name: msa_network
        driver: bridge
# docker-compose up

# docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic session-topic --from-beginning
# docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic streaming --from-beginning
# docker exec -it kafka kafka-console-consumer --bootstrap-server kafka:9092 --topic spring-logs --from-beginning
# docker exec -it kafka kafka-console-consumer --bootstrap-server kafka:9092 --topic beats-logs --from-beginning
# docker exec -it kafka kafka-topics --bootstrap-server kafka:9092 --describe --topic spring-logs

# redis-cli -h localhost -p 6379
# get
